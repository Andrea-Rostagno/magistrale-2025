# Caricamento delle librerie necessarie
library(datasets) # Dataset di esempio
library(catdata) # Dati categoriali
library(dslabs) # Dataset vari
library(mvtnorm) # Multivariate normal
library(patchwork) # Combinazione di plot ggplot2
library(paletteer) # Palette di colori
library(tidyverse) # Collezione di pacchetti per data science
# In R, per ogni distribuzione esistono 4 funzioni principali:
# d* = densità/probabilità, p* = cumulata, q* = quantile, r* = generazione casuale
# Esempi:
#   dnorm(), pnorm(), qnorm(), rnorm() per la normale
#   dexp(), pexp(), qexp(), rexp() per l'esponenziale
#   dpois(), ppois(), qpois(), rpois() per la Poisson
?dnorm # Help sulla densità della normale
?dexp # Help sulla densità dell'esponenziale
?dpois # Help sulla densità della Poisson
z_scores <- seq(-4, 4, by = 0.01) # intervallo di z-score
mu <- 0 # media
sd <- 1 # deviazione standard
# Costruzione di un data frame con le funzioni principali della normale
normal_dists <- list(
`dnorm()` = ~ dnorm(., mu, sd), # Densità
`rnorm()` = ~ dnorm(., mu, sd), # Valori simulati (qui usato come densità)
`pnorm()` = ~ pnorm(., mu, sd), # Cumulata
`qnorm()` = ~ pnorm(., mu, sd) # Cumulata (per confronto)
)
# Applica le funzioni e prepara i dati per il plotting
df <- tibble(z_scores, mu, sd) %>%
mutate_at(.vars = vars(z_scores), .funs = normal_dists) %>%
pivot_longer(
cols = -c(z_scores, mu, sd), names_to = "func",
values_to = "prob"
) %>%
mutate(distribution = ifelse(func == "pnorm()" | func == "qnorm()",
"Cumulative probability", "Probability density"
))
# Separazione dei dati per tipo di funzione (densità/cumulata)
df_pdf <- df %>%
filter(distribution == "Probability density") %>%
rename(`Probabilitiy density` = prob)
df_cdf <- df %>%
filter(distribution == "Cumulative probability") %>%
rename(`Cumulative probability` = prob)
# Segmenti per illustrare la densità (dnorm)
df_dnorm <- tibble(
z_start.line_1 = c(-1.5, -0.75, 0.5),
pd_start.line_1 = 0
) %>%
mutate(
z_end.line_1 = z_start.line_1,
pd_end.line_1 = dnorm(z_end.line_1, mu, sd),
z_start.line_2 = z_end.line_1,
pd_start.line_2 = pd_end.line_1,
z_end.line_2 = min(z_scores),
pd_end.line_2 = pd_start.line_2,
id = 1:n()
) %>%
pivot_longer(-id) %>%
separate(name, into = c("source", "line"), sep = "\\.") %>%
pivot_wider(id_cols = c(id, line), names_from = source) %>%
mutate(
func = "dnorm()",
size = ifelse(line == "line_1", 0, 0.03)
)
# Segmenti per illustrare valori simulati (rnorm)
set.seed(20200209)
df_rnorm <- tibble(z_start = rnorm(10, mu, sd)) %>%
mutate(
pd_start = dnorm(z_start, mu, sd),
z_end = z_start,
pd_end = 0,
func = "rnorm()"
)
# Segmenti per illustrare la cumulata (pnorm)
df_pnorm <- tibble(
z_start.line_1 = c(-1.5, -0.75, 0.5),
pd_start.line_1 = 0
) %>%
mutate(
z_end.line_1 = z_start.line_1,
pd_end.line_1 = pnorm(z_end.line_1, mu, sd),
z_start.line_2 = z_end.line_1,
pd_start.line_2 = pd_end.line_1,
z_end.line_2 = min(z_scores),
pd_end.line_2 = pd_start.line_2,
id = 1:n()
) %>%
pivot_longer(-id) %>%
separate(name, into = c("source", "line"), sep = "\\.") %>%
pivot_wider(id_cols = c(id, line), names_from = source) %>%
mutate(
func = "pnorm()",
size = ifelse(line == "line_1", 0, 0.03)
)
# Segmenti per illustrare la funzione quantile (qnorm)
df_qnorm <- tibble(
z_start.line_1 = min(z_scores),
pd_start.line_1 = c(0.1, 0.45, 0.85)
) %>%
mutate(
z_end.line_1 = qnorm(pd_start.line_1),
pd_end.line_1 = pd_start.line_1,
z_start.line_2 = z_end.line_1,
pd_start.line_2 = pd_end.line_1,
z_end.line_2 = z_end.line_1,
pd_end.line_2 = 0,
id = 1:n()
) %>%
pivot_longer(-id) %>%
separate(name, into = c("source", "line"), sep = "\\.") %>%
pivot_wider(id_cols = c(id, line), names_from = source) %>%
mutate(
func = "qnorm()",
size = ifelse(line == "line_1", 0, 0.03)
)
# Palette di colori per i plot
cp <- paletteer_d("ggsci::default_locuszoom", 4, )
names(cp) <- c("dnorm()", "rnorm()", "pnorm()", "qnorm()")
# Plot della densità di probabilità
p_pdf <- df_pdf %>%
ggplot(aes(z_scores, `Probabilitiy density`)) +
geom_segment(
data = df_dnorm,
aes(z_start, pd_start, xend = z_end, yend = pd_end),
arrow = arrow(length = unit(df_dnorm$size, "npc"), type = "closed"),
size = 0.8, color = cp["dnorm()"]
) +
geom_segment(
data = df_rnorm,
aes(z_start, pd_start, xend = z_end, yend = pd_end),
arrow = arrow(length = unit(0.03, "npc"), type = "closed"),
size = 0.8, color = cp["rnorm()"]
) +
geom_line(size = 0.6) +
facet_wrap(~func, nrow = 1) +
theme_bw() +
theme(
panel.grid = element_blank(),
axis.title.x = element_blank(),
strip.background = element_blank(),
text = element_text(family = "serif", size = 14)
) +
scale_y_continuous(expand = expand_scale(c(0, 0.05))) +
scale_x_continuous(expand = c(0.01, 0))
# Plot della probabilità cumulata
p_cdf <- df_cdf %>%
ggplot(aes(z_scores, `Cumulative probability`)) +
geom_hline(yintercept = 0, color = "grey") +
geom_segment(
data = df_pnorm,
aes(z_start, pd_start, xend = z_end, yend = pd_end),
arrow = arrow(length = unit(df_dnorm$size, "npc"), type = "closed"),
size = 0.8, color = cp["pnorm()"]
) +
geom_segment(
data = df_qnorm,
aes(z_start, pd_start, xend = z_end, yend = pd_end),
arrow = arrow(length = unit(df_qnorm$size, "npc"), type = "closed"),
size = 0.8, color = cp["qnorm()"]
) +
geom_line(size = 0.6) +
facet_wrap(~func, nrow = 1) +
labs(x = "z-score/quantiles") +
theme_bw() +
theme(
panel.grid = element_blank(),
strip.background = element_blank(),
text = element_text(family = "serif", size = 14)
) +
scale_x_continuous(expand = c(0.01, 0))
# Combina i due plot (densità e cumulata)
p_pdf + p_cdf + plot_layout(ncol = 1)
# ============================================================
# Esempio: effetto del seed sulla generazione di numeri casuali
# ============================================================
set.seed(100)
runif(10, 0, 1)
set.seed(100)
runif(10, 0, 1)
runif(10, 0, 1)
# Generatore congruenziale lineare per U(0,1)
r_unif01 <- function(n, seed, m = 100, c = 2, a = 4) {
# Controllo parametri
if ((c < 0) | (c > m)) {
stop("(c<0) | (c>m)")
}
if ((a <= 0) | (a >= m)) {
stop("(a<=0) | (a>=m)")
}
ret <- rep(NA, n) # Vettore risultato
prev_val <- seed # Valore iniziale (seed)
for (i in 1:n)
{
ret[i] <- (a * prev_val + c) %% m # Ricorrenza congruenziale
prev_val <- ret[i]
}
return(ret / m) # Normalizza in [0,1]
}
x <- r_unif01(n = 100000, seed = 0, m = 1000, c = 3, a = 5)
par(mfrow = c(1, 2))
plot(x)
hist(x)
table(x)
x <- r_unif01(n = 100000, seed = 0, m = 1000000, c = 3.3, a = 5.3)
par(mfrow = c(1, 2))
plot(x)
hist(x)
table(table(x))
x <- r_unif01(n = 100000, seed = 0, m = 1000000, c = 3.7, a = 30.3)
par(mfrow = c(1, 2))
plot(x)
hist(x)
table(table(x))
rmnorm <- function(n = 1, mean = rep(0, d), varcov) {
# n: numero di campioni
# mean: vettore delle medie
# varcov: matrice di varianza-covarianza
d <- if (is.matrix(varcov)) {
ncol(varcov)
} else {
1
}
z <- matrix(rnorm(n * d), n, d) %*% chol(varcov) # campioni standard
y <- t(mean + t(z)) # traslazione
return(y)
}
n <- 10000
mu <- matrix(c(1, 2), ncol = 1)
A <- matrix(runif(4, 0, 1), ncol = 2)
Sigma <- A %*% t(A)
u1 <- runif(n)
u2 <- runif(n)
x <- sqrt(-2 * log(u1)) * cos(2 * pi * u2)
y <- sqrt(-2 * log(u1)) * sin(2 * pi * u2)
norm_var1 <- t(A %*% rbind(x, y) + matrix(mu, ncol = n, nrow = 2))
norm_var2 <- rmnorm(n, c(mu), Sigma)
# norm_var1 = rbind(x,y)
par(mfrow = c(1, 2))
smoothScatter(norm_var1)
smoothScatter(norm_var2)
x <- seq(0, 20, by = 0.1)
par(mfrow = c(1, 1))
plot(x, ppois(x, 2), type = "s")
x <- seq(0, 20, by = 0.1)
par(mfrow = c(1, 1))
plot(x, pgamma(x, 1, 1), type = "s")
K <- 5
prob_mat <- matrix(runif(K^2, 0, 1), ncol = K)
prob_mat <- round(prob_mat / sum(prob_mat), 3)
prob_mat
# campioniamo
n <- 10000
# prima x1, poi x2
x1 <- sample(1:K, n, prob = rowSums(prob_mat), replace = T)
x2 <- rep(NA, n)
for (i in 1:n)
{
x2[i] <- sample(1:K, 1, prob = prob_mat[x1[i], ] / sum(prob_mat[x1[i], ]), replace = T)
}
matrix_conteggi1 <- matrix(0, ncol = K, nrow = K)
for (i in 1:n)
{
matrix_conteggi1[x1[i], x2[i]] <- matrix_conteggi1[x1[i], x2[i]] + 1
}
# prima x2, poi x1
x2 <- sample(1:K, n, prob = colSums(prob_mat), replace = T)
x1 <- rep(NA, n)
for (i in 1:n)
{
x1[i] <- sample(1:K, 1, prob = prob_mat[, x2[i]] / sum(prob_mat[, x2[i]]), replace = T)
}
matrix_conteggi2 <- matrix(0, ncol = K, nrow = K)
for (i in 1:n)
{
matrix_conteggi2[x1[i], x2[i]] <- matrix_conteggi2[x1[i], x2[i]] + 1
}
matrix_conteggi1 / n
matrix_conteggi2 / n
prob_mat
# ============================================================
# Teorema Accept-Reject: visualizzazione dominio accettazione
# ============================================================
library(plotly)
# assumiamo x da  G(9,2)
n <- 100
x <- seq(0, 10, length.out = n)
fx <- dgamma(x, shape = 9, rate = 2)
m <- max(fx)
u <- seq(0, m, length.out = n)
dens <- matrix(0, nrow = n, ncol = n)
for (i in 1:n)
{
for (j in 1:n)
{
if (u[j] < fx[i]) {
dens[i, j] <- 1
}
}
}
pp <- plot_ly(x = x, y = u, z = t(dens), type = "surface")
layout(pp,
scene = list(
xaxis = list(title = "x"),
yaxis = list(title = "u"),
zaxis = list(title = "dens")
)
)
# simulazione
n <- 10
x <- rgamma(n, 2, 2)
# scegliamo i parametri di un kernel gaussiano
# con diversi parametri
stand_dev_1 <- 0.0001
stand_dev_2 <- 0.05
stand_dev_3 <- 0.5
# calcoliamo la stima di densità in xseq
xseq <- seq(0, 10, by = 0.1)
stima_dens_1 <- c()
stima_dens_2 <- c()
